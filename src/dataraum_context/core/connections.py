"""Thread-safe connection management for SQLAlchemy + DuckDB.

This module provides concurrent-ready connection management:
- SQLAlchemy async sessions with connection pooling
- DuckDB with read cursors and serialized writes
- WAL mode for SQLite to enable concurrent reads with writes

Usage:
    from dataraum_context.core.connections import ConnectionManager, ConnectionConfig

    config = ConnectionConfig.for_directory(Path("./output"))
    manager = ConnectionManager(config)
    await manager.initialize()

    # Get a session (from pool)
    async with manager.session_scope() as session:
        # Use session...

    # Read from DuckDB (concurrent-safe via cursor)
    with manager.duckdb_cursor() as cursor:
        result = cursor.execute("SELECT * FROM table").fetchdf()

    # Write to DuckDB (serialized via mutex)
    with manager.duckdb_write() as conn:
        conn.execute("INSERT INTO table VALUES (...)")

    await manager.close()
"""

from __future__ import annotations

import asyncio
import threading
from collections.abc import Generator
from contextlib import asynccontextmanager, contextmanager
from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Any

import duckdb
from sqlalchemy import event, text
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.pool import NullPool

from dataraum_context.storage import Base

if TYPE_CHECKING:
    from collections.abc import AsyncGenerator


@dataclass
class ConnectionConfig:
    """Connection configuration for SQLAlchemy and DuckDB.

    Attributes:
        sqlite_path: Path to SQLite database file
        duckdb_path: Path to DuckDB database file
        pool_size: SQLAlchemy connection pool size
        max_overflow: Maximum overflow connections beyond pool_size
        pool_timeout: Seconds to wait for a connection from pool
        sqlite_timeout: SQLite busy timeout in seconds
        duckdb_memory_limit: DuckDB memory limit (e.g., "2GB")
        echo_sql: Whether to echo SQL statements (for debugging)
    """

    sqlite_path: Path
    duckdb_path: Path

    # SQLAlchemy pool settings
    pool_size: int = 5
    max_overflow: int = 10
    pool_timeout: float = 30.0
    sqlite_timeout: float = 30.0

    # DuckDB settings
    duckdb_memory_limit: str = "2GB"

    # Debug
    echo_sql: bool = False

    @classmethod
    def for_directory(cls, output_dir: Path, **kwargs: Any) -> ConnectionConfig:
        """Create config for a pipeline output directory.

        Args:
            output_dir: Directory for database files
            **kwargs: Override any config attributes

        Returns:
            ConnectionConfig with paths set to output_dir
        """
        return cls(
            sqlite_path=output_dir / "metadata.db",
            duckdb_path=output_dir / "data.duckdb",
            **kwargs,
        )

    @classmethod
    def in_memory(cls, **kwargs: Any) -> ConnectionConfig:
        """Create config for in-memory databases (useful for testing).

        Args:
            **kwargs: Override any config attributes

        Returns:
            ConnectionConfig with in-memory paths
        """
        return cls(
            sqlite_path=Path(":memory:"),
            duckdb_path=Path(":memory:"),
            **kwargs,
        )


@dataclass
class ConnectionManager:
    """Thread-safe connection management for SQLAlchemy + DuckDB.

    Provides:
    - SQLAlchemy async session factory with connection pooling
    - DuckDB read access via cursors (concurrent-safe)
    - DuckDB write access via mutex (serialized)
    - Proper cleanup on close

    Thread Safety:
    - SQLAlchemy sessions: One session per async task (from pool)
    - DuckDB reads: Use cursor() which is thread-safe for reads
    - DuckDB writes: Serialized via _write_lock mutex

    Usage:
        manager = ConnectionManager(config)
        await manager.initialize()

        async with manager.session_scope() as session:
            # SQLAlchemy operations...

        with manager.duckdb_cursor() as cursor:
            df = cursor.execute("SELECT ...").fetchdf()

        with manager.duckdb_write() as conn:
            conn.execute("INSERT ...")

        await manager.close()
    """

    config: ConnectionConfig
    _engine: AsyncEngine | None = field(default=None, init=False, repr=False)
    _session_factory: async_sessionmaker[AsyncSession] | None = field(
        default=None, init=False, repr=False
    )
    _duckdb_conn: duckdb.DuckDBPyConnection | None = field(default=None, init=False, repr=False)
    _write_lock: threading.Lock = field(default_factory=threading.Lock, init=False, repr=False)
    _initialized: bool = field(default=False, init=False, repr=False)
    _init_lock: asyncio.Lock = field(default_factory=asyncio.Lock, init=False, repr=False)

    async def initialize(self) -> None:
        """Initialize connection pools and databases.

        Creates SQLAlchemy engine with connection pool and DuckDB connection.
        Safe to call multiple times (idempotent).

        Raises:
            RuntimeError: If initialization fails
        """
        async with self._init_lock:
            if self._initialized:
                return

            try:
                await self._init_sqlalchemy()
                self._init_duckdb()
                self._initialized = True
            except Exception as e:
                await self.close()
                raise RuntimeError(f"Failed to initialize connections: {e}") from e

    async def _init_sqlalchemy(self) -> None:
        """Initialize SQLAlchemy async engine with connection pool."""
        # Handle in-memory vs file-based SQLite
        if self.config.sqlite_path == Path(":memory:"):
            db_url = "sqlite+aiosqlite:///:memory:"
        else:
            self.config.sqlite_path.parent.mkdir(parents=True, exist_ok=True)
            db_url = f"sqlite+aiosqlite:///{self.config.sqlite_path}"

        # Use NullPool to allow the engine to work across multiple event loops
        # (required for ThreadPoolExecutor with asyncio.run() in each thread)
        # See: https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html#using-multiple-asyncio-event-loops
        self._engine = create_async_engine(
            db_url,
            echo=self.config.echo_sql,
            poolclass=NullPool,
        )

        # Configure SQLite pragmas on each connection
        @event.listens_for(self._engine.sync_engine, "connect")
        def configure_sqlite(dbapi_conn: Any, connection_record: Any) -> None:
            cursor = dbapi_conn.cursor()
            # Enable foreign keys
            cursor.execute("PRAGMA foreign_keys=ON")
            # Use WAL mode for better concurrency (readers don't block writers)
            cursor.execute("PRAGMA journal_mode=WAL")
            # Set busy timeout (milliseconds)
            cursor.execute(f"PRAGMA busy_timeout={int(self.config.sqlite_timeout * 1000)}")
            # Synchronous mode - NORMAL is good balance of safety/speed
            cursor.execute("PRAGMA synchronous=NORMAL")
            cursor.close()

        # Import all models to register them with SQLAlchemy
        self._import_all_models()

        # Create tables
        async with self._engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)

        # Create session factory
        self._session_factory = async_sessionmaker(
            self._engine,
            class_=AsyncSession,
            expire_on_commit=False,
        )

    def _init_duckdb(self) -> None:
        """Initialize DuckDB connection."""
        if self.config.duckdb_path == Path(":memory:"):
            self._duckdb_conn = duckdb.connect(":memory:")
        else:
            self.config.duckdb_path.parent.mkdir(parents=True, exist_ok=True)
            self._duckdb_conn = duckdb.connect(str(self.config.duckdb_path))

        # Configure DuckDB
        self._duckdb_conn.execute(f"SET memory_limit='{self.config.duckdb_memory_limit}'")

    def _import_all_models(self) -> None:
        """Import all DB model modules to register them with SQLAlchemy."""
        # Import all modules that define SQLAlchemy models
        # This ensures Base.metadata has all tables before create_all()
        from dataraum_context.analysis.correlation import db_models as _correlation  # noqa: F401
        from dataraum_context.analysis.cycles import db_models as _cycles  # noqa: F401
        from dataraum_context.analysis.quality_summary import db_models as _quality  # noqa: F401
        from dataraum_context.analysis.relationships import db_models as _rel  # noqa: F401
        from dataraum_context.analysis.semantic import db_models as _semantic  # noqa: F401
        from dataraum_context.analysis.slicing import db_models as _slicing  # noqa: F401
        from dataraum_context.analysis.statistics import db_models as _statistics  # noqa: F401
        from dataraum_context.analysis.temporal import db_models as _temporal  # noqa: F401
        from dataraum_context.analysis.temporal_slicing import (
            db_models as _temp_slice,  # noqa: F401
        )
        from dataraum_context.analysis.topology import db_models as _topology  # noqa: F401
        from dataraum_context.analysis.typing import db_models as _typing  # noqa: F401
        from dataraum_context.analysis.validation import db_models as _validation  # noqa: F401
        from dataraum_context.entropy import db_models as _entropy  # noqa: F401
        from dataraum_context.graphs import db_models as _graphs  # noqa: F401
        from dataraum_context.llm import db_models as _llm  # noqa: F401
        from dataraum_context.pipeline import db_models as _pipeline  # noqa: F401

    def _ensure_initialized(self) -> None:
        """Raise if not initialized."""
        if not self._initialized:
            raise RuntimeError(
                "ConnectionManager not initialized. Call await manager.initialize() first."
            )

    @asynccontextmanager
    async def session_scope(self) -> AsyncGenerator[AsyncSession]:
        """Get a session from the pool with automatic cleanup.

        Yields:
            AsyncSession from the connection pool

        Raises:
            RuntimeError: If manager not initialized

        Example:
            async with manager.session_scope() as session:
                result = await session.execute(select(Table))
        """
        self._ensure_initialized()
        assert self._session_factory is not None

        session = self._session_factory()
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()

    async def get_session(self) -> AsyncSession:
        """Get a new session from the pool.

        The caller is responsible for committing/closing the session.
        Prefer session_scope() for automatic cleanup.

        Returns:
            New AsyncSession from pool

        Raises:
            RuntimeError: If manager not initialized
        """
        self._ensure_initialized()
        assert self._session_factory is not None
        return self._session_factory()

    @contextmanager
    def duckdb_cursor(self) -> Generator[duckdb.DuckDBPyConnection]:
        """Get a DuckDB cursor for read operations.

        Cursors from the same connection are thread-safe for reads.
        Use this for SELECT queries that don't modify data.

        Yields:
            DuckDB cursor for read operations

        Raises:
            RuntimeError: If manager not initialized

        Example:
            with manager.duckdb_cursor() as cursor:
                df = cursor.execute("SELECT * FROM table").fetchdf()
        """
        self._ensure_initialized()
        assert self._duckdb_conn is not None

        cursor = self._duckdb_conn.cursor()
        try:
            yield cursor
        finally:
            cursor.close()

    @contextmanager
    def duckdb_write(self) -> Generator[duckdb.DuckDBPyConnection]:
        """Get exclusive write access to DuckDB.

        Uses mutex to serialize all write operations.
        Use this for INSERT, UPDATE, DELETE, CREATE TABLE, etc.

        Yields:
            DuckDB connection with exclusive write access

        Raises:
            RuntimeError: If manager not initialized

        Example:
            with manager.duckdb_write() as conn:
                conn.execute("INSERT INTO table VALUES (...)")
        """
        self._ensure_initialized()
        assert self._duckdb_conn is not None

        with self._write_lock:
            yield self._duckdb_conn

    @property
    def duckdb_conn(self) -> duckdb.DuckDBPyConnection:
        """Get the underlying DuckDB connection.

        Warning: Direct access bypasses write serialization.
        Use duckdb_cursor() for reads and duckdb_write() for writes.

        Returns:
            The DuckDB connection

        Raises:
            RuntimeError: If manager not initialized
        """
        self._ensure_initialized()
        assert self._duckdb_conn is not None
        return self._duckdb_conn

    @property
    def engine(self) -> AsyncEngine:
        """Get the SQLAlchemy async engine.

        Returns:
            The AsyncEngine instance

        Raises:
            RuntimeError: If manager not initialized
        """
        self._ensure_initialized()
        assert self._engine is not None
        return self._engine

    async def close(self) -> None:
        """Close all connections and dispose of pools.

        Safe to call multiple times.
        """
        if self._duckdb_conn is not None:
            try:
                self._duckdb_conn.close()
            except Exception:
                pass
            self._duckdb_conn = None

        if self._engine is not None:
            try:
                await self._engine.dispose()
            except Exception:
                pass
            self._engine = None

        self._session_factory = None
        self._initialized = False

    async def execute_sqlite(self, sql: str) -> Any:
        """Execute raw SQL on SQLite (for debugging/admin).

        Args:
            sql: SQL statement to execute

        Returns:
            Result of execution
        """
        self._ensure_initialized()
        assert self._engine is not None

        async with self._engine.begin() as conn:
            return await conn.execute(text(sql))

    async def get_stats(self) -> dict[str, Any]:
        """Get connection pool statistics.

        Returns:
            Dict with pool status information
        """
        self._ensure_initialized()
        assert self._engine is not None

        pool: Any = self._engine.pool
        return {
            "sqlite_pool_size": pool.size() if hasattr(pool, "size") else None,
            "sqlite_checked_out": pool.checkedout() if hasattr(pool, "checkedout") else None,
            "sqlite_overflow": pool.overflow() if hasattr(pool, "overflow") else None,
            "sqlite_checked_in": pool.checkedin() if hasattr(pool, "checkedin") else None,
            "duckdb_connected": self._duckdb_conn is not None,
        }


# Convenience function for simple scripts
_default_manager: ConnectionManager | None = None


async def get_connection_manager(
    output_dir: Path | None = None,
    config: ConnectionConfig | None = None,
) -> ConnectionManager:
    """Get or create a default ConnectionManager.

    For simple scripts that don't need multiple managers.
    Creates a singleton manager on first call.

    Args:
        output_dir: Output directory (used if config not provided)
        config: Full configuration (takes precedence over output_dir)

    Returns:
        Initialized ConnectionManager
    """
    global _default_manager

    if _default_manager is None:
        if config is None:
            if output_dir is None:
                output_dir = Path("./pipeline_output")
            config = ConnectionConfig.for_directory(output_dir)

        _default_manager = ConnectionManager(config)
        await _default_manager.initialize()

    return _default_manager


async def close_default_manager() -> None:
    """Close the default ConnectionManager if it exists."""
    global _default_manager

    if _default_manager is not None:
        await _default_manager.close()
        _default_manager = None


__all__ = [
    "ConnectionConfig",
    "ConnectionManager",
    "get_connection_manager",
    "close_default_manager",
]
